mentions: static thresholds, push v pull, data summarization

# A Few things you should know about monitoring systems

## Smaller is better
New monitoring systems spring into being for myriad reasons. The best ones come
from engineers like you who couldn't find the tool they needed to get their
work done. These tools tend to be small, efficient, and purpose-specific. They
tend to get along well with other tools, and they solve more problems than they
create.  Other tools don't do these things. They come from people who were
looking for a market niche who say things like "THIS tool can monitor ANYTHING
with ZERO EFFORT!". 

Monitoring tools excel when they start with a very strong focus and iterate on
it until it's rock-solid.  This book exists today to more or less deliver this
message: beware the tool that claims to do it all, because today, as I write
this, the reality is there probaby isn't one tool that's going to take care of
everything for your orginazation as a whole. It's really not a question of
features, it's a question of trade-offs. 

Simple tools often have scaling problems. But then again, tools that scale well
are often difficult to maintain.  Tools that are easy to maintain are often
expensive, and cheaper tools tend to become more widely adopted throughout the
organization, and on and on. The combination of tools you'll eventually choose
should have way more to do with the people around you, and things like how much
money and time you have, than how many thingies the monitoring system claims to
be able to watch.

But even if that weren't true -- if we could ignore the human factors invovled
here, there certainly is no single monitoring tool that has this entire problem
licked, and that's just a laws of physics thing. As you'll see below, if you
need raw-resolution data, you're going to have to store less of it, or foot the
bill for a large stream-processing and storage infrastructure. If you want
flexibility with respect to *how* a tool monitors the things you care about,
you'll have to develop some in-house expertiese to maintain your
customizations. For every advantage there's a trade-off. That's just the way it
is. As my Mom used to say: Them's the breaks kid.

So if you find yourself considering a tool that claims to be the final and
ultimate solution to the monitoring problem, my advice is to assume you're
working with a tool (or more likely a salesperson) that doesn't understand the
problem very well and move on.  You want to be using tools that are savvy to,
and up-front about their limitations.

## Push vs Pull

## Data summarization and storage
Time series databases are really hard. Anyone who says otherwise is trying to
sell you something. It really doesn't matter how large you are today or how
much you're trying to measure, you can't afford to store raw-resolution data
(unless you can afford a hadoop infratructure for metrics alone). So pretty
much every TSDB performs some form of data summarization (also referred to as
aggregation or rollups). The idea is to consolidate the individual data points
you collect into fewer datapoints that accurately summarize the original
measurements.

I don't have the room to devle very deeply into this subject but it's been
widely documented and you should read up. Monitoring systems vary widely in how
they accomplish data aggregation, which is relevent to you because you want to
ensure that your data isn't destroyed in the summarization process. On one
extreme are the systems that expose all of the dials and knobs to you, giving
you all the rope you need to hang yourself and walking away, while on the other
are the systems which try to insulate you by destroying your data and assuming
you're too stupid and apathetic to know the difference. 

Good monitoring systems are very up-front and clear about their data retention
and resolution schedules. They'll say "we store 1-second resolution data for X
days, and then we agregate it by doing Y". Be careful with systems that don't
provide this information, because they're probably averaging your data into
oblivion without telling you. Most systems will make you classify your inbound
metrics, assigning to them types like "gauge", "counter", or "timer". Make sure
you understand how the system you choose uses those classifications. Some
systems will automatically assign destructive roll-ups to certain types, always
applying mean-average to consolidate gauge metrics for example.

"How does your system treat gauge metrics versus counter metrics in the
persistence layer?" is a great question to ask the pre-sales engineer sitting in
your conference room.

Finally, several systems employ "data-point capping", which I have mixed
feelings about.  That is, regardless of storage resolution, their UI will only
display X datapoints per graph (usually a number in the range 300-800),
effectively limiting the amount of raw-resolution data you're allowed to see at
once (the system will automatically switch to courser resolution when you
stretch the X-axis). I completely understand the impulse behind this but I
personally find that impulse more than a little patronizing. The cynic in me
suspects systems that do this are choosing responsive UI over data resolution
to protect the help-desk from complaints about slow graphs, and as an end-user
who is using the system in a problem solving capacity, I feel that's a mistake
I should be allowed make when I need to.

## Auto-discovery
Beware tools that tout auto-discovery as a feature. If you don't know how many
systems you have, how they are attached to the network, and which ones have
databases and which ones have web servers, you have bigger problems than
monitoring. Configuration management has more than killed the need for
network-scanning autodiscovery features inside monitoring systems (which
honestly never worked very well anyway). Every type of infrastructure
maintenance software you can imagine exists in one form or another today (I
recommend saltstack), so adopt something and use it to roll out your monitoring
agents and maintain state across your network. 

I should note I'm not talking about the autodiscovery used by APM systems like
Appdynamics and Ruxit who are trying to draw context from your infrastructure
that can be used as input to some larger machine-learning computation. If you
find that stuff helpful run with it, but yes, aside from those systems who have
loftier goals of their own, be careful with monitoring tools that are still
excited about autodiscovery. Make sure they're not actually just accidently
confessing their lack of configuration-management support. Think about your
configuration management strategy and how this monitoring tool might fit into
it, and run away if it feels like the tool might impede or otherwise complicate
your ability to centrally manage the software on your servers.

# A Few types of monitoring systems

## APM
The problem with distributed web architectures is that they're so...
distributed. Your code is slathered from inside the end-users browser all the
way back to the Database (which you've heard is somewhere in Pittsburg).
Application Performance Monitoring, or APM tries to measure the performance
characteristics of a web-application from one end to the other; breaking down
how long every little hunk of code took to do it's thing, so when someone says
"the website is slow" you can hopefully see where you need to go to fix it.

Typically these tools use Bytecode injection and/or Monkey-patching to modify
your code, compiler or interpretor at run-time, wrapping classes and functions
with versions that extract timing information.  Those timing numbers are then
emitted as metrics and sent into the APM's data collection framework. Data
resolution and retention varies widely, though many of these tools work on a
60-second tick, which is perfectly adequate in real life.

In my admittedly limited experience (and no-doubt already tiresome opinion),
APM tools remain effective by retaining their focus on augmenting engineering
know-how and otherwise staying out of the way. Many do this well, and many
others sprawl here and there in an attempt to find novel uses for machine
learning or impress management with world-maps, doughnut-graphs and node/edge
diagrams. Don't get me wrong, many of these features are nifty, and helpful for
non-technical users. That's great, but beware tools that put that stuff first
-- actually making you click through maps to get to timing data or otherwise
attempting to enforce their interpretation of your architecture in the UI in
ways that make you work around it. You're going to want simple line-graphs of
timing data way more often than you're going to want a map, and you're going to
be using the tool more often than non-technical users (assuming it actually
works).

## RUM
RUM, or "Real User Monitoring" used to be a thing before it was swallowed by
APM. The idea is, since you have javascript running inside your user's browser,
you may as well inject a timer or two, just to see how long it took that user
to load your page. RUM is probably the biggest deal in web-performance
monitoring in the last decade or so. It's really helping people who want pages
to load faster close the loop with the people who are working to make those
pages load faster.

There aren't very many RUM-only tools out there (none are represented in this
book) because RUM has largly become a feature of the various APM systems. Bucky
(http://github.hubspot.com/bucky/) is a good open source library if you're just
looking for some stand-alone RUM.

## Exception Tracking

Exception tracking systems count crashes (In polite society we refer to them as
"exceptions"). They usually do this from within web-based applications
server-side, or in code running in your user's browser on the client-side. They
often walk the line between RUM and Log-Processing systems, having neither the
open-endedness of logging systems nor the performance-centric focus of RUM.
Their simplicity and single-mindedness make them cheap, easy to configure,
simple to use, and very reliable. A collection of happy factors that combine to
often make them the go-to application monitoring solution when centralized
logging is too much of a hassle, and APM/RUM is too hulking, confusing,
unreliable and/or expensive. 

These tools generally rely on the exception handling charateristics built-in to
languages like Java and Python; giving you a function to call when exceptions
happen or a function to wrap dangerous code in for languages that implement
error handeling instead. Since the data is a-periodic (hopefully your code only
crashes so often) and finite (there are only so many ways it can crash), these
systems almost always store raw-resolution data to relational data-stores, and
boast simple, effective UI's. Beware that because browser quality varies so
drastically, the data you get from these tools browser-side will also very
drastrically. 

### Remote Polling
